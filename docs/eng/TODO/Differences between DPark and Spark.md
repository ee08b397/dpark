DPark虽然是Spark的Python克隆版本，但是由于Python和Scala的区别和特性，他们之间有一些不同：

1. 两者之间最重要的区别就是线程和进程的区别。在Spark中使用的是一个线程来运行一个任务，而DPark是用的进程。原因如下：在Python当中，由于GIL的存在，即使在多核机器上使用多个线程，这些线程之间也没有办法真正的实现并发执行，在现在的集群计算中，机器大多是多核的，Master会将一个任务分配到一个计算节点的一个CPU中运行，以充分利用每一台计算节点，但是由于GIL的存在，如果我们使用线程来运行每一个任务，那么会导致同一个计算节点上至多只有一个线程能够被运行，大大降低了计算的速度，所以我们不得不采用进程来运行每一个任务。而这个就导致了`cache`之后在同一个计算节点的各个任务之间共享内存变得相对复杂，并会带来一些额外的开销，我们在努力使得这一开销尽量降低。
1. 支持的文件系统不同。Spark使用了Hadoop框架中提供的关于文件系统的接口，所以只要Hadoop支持的文件系统和文件格式，Spark都能支持。而DPark无法直接使用Hadoop的代码和接口，所以只能使用Posix文件系统，或者为某种文件系统参照textFile实现特定的接口。目前DPark支持所有能以FUSE或者类似方式访问的文件系统，包括MFS、NFS等类似系统，HDFS有FUSE接口可以使用。DPark特别针对MFS文件系统实现了一种RDD，它可以绕过FUSE，得到文件的分布信息，方便进行IO本地优化。

